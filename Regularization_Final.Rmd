---
title: "Regularization"
author: "Roshan Pimple"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F)
```

# Data Understanding

```{r}
set.seed(123)
suppressPackageStartupMessages(library(glmnet))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
```

Our task is to predict the price of an automobile based on several independent variables.

Attribute: Attribute Range 

1. symboling: -3, -2, -1, 0, 1, 2, 3. 
2. normalized-losses: continuous from 65 to 256. 
3. make: 
alfa-romero, audi, bmw, chevrolet, dodge, honda, 
isuzu, jaguar, mazda, mercedes-benz, mercury, 
mitsubishi, nissan, peugot, plymouth, porsche, 
renault, saab, subaru, toyota, volkswagen, volvo 

4. fuel-type: diesel, gas. 
5. aspiration: std, turbo. 
6. num-of-doors: four, two. 
7. body-style: hardtop, wagon, sedan, hatchback, convertible. 
8. drive-wheels: 4wd, fwd, rwd. 
9. engine-location: front, rear. 
10. wheel-base: continuous from 86.6 120.9. 
11. length: continuous from 141.1 to 208.1. 
12. width: continuous from 60.3 to 72.3. 
13. height: continuous from 47.8 to 59.8. 
14. curb-weight: continuous from 1488 to 4066. 
15. engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor. 
16. num-of-cylinders: eight, five, four, six, three, twelve, two. 
17. engine-size: continuous from 61 to 326. 
18. fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi. 
19. bore: continuous from 2.54 to 3.94. 
20. stroke: continuous from 2.07 to 4.17. 
21. compression-ratio: continuous from 7 to 23. 
22. horsepower: continuous from 48 to 288. 
23. peak-rpm: continuous from 4150 to 6600. 
24. city-mpg: continuous from 13 to 49. 
25. highway-mpg: continuous from 16 to 54. 
26. price: continuous from 5118 to 45400.

# Data Preparation

## Data Import

```{r}
# if file does not exist, download it first
file_path <- "./data/automobile.csv"
if (!file.exists(file_path)) {
  dir.create("./data")
  url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
  download.file(url = url, 
                destfile = file_path)
}

cars <- read.csv(file_path, sep = ",", header = F)
colnames(cars) <- c("symboling", "normalized_losses", "make", "fuel_type", "aspiration", "num_of_doors", "body_style", "drive_wheels", "engine_location", "wheel_base", "length", "width","height", "curb_weight", "engine_type", "num_of_cylinders", "engine_size", "fuel_system", "bore", "stroke", "compression_ratio", "horsepower", "peak_rpm", "city_mpg", "highway_mpg", "price")
cars$price <- as.numeric(cars$price)
cars$horsepower <- as.numeric(cars$horsepower)
cars$peak_rpm <- as.numeric(cars$peak_rpm)
cars$normalized_losses <- as.numeric(cars$normalized_losses)
```

## Data Filtering

```{r}
cars_filt <- cars %>% 
  dplyr::select(symboling, normalized_losses, wheel_base, length, width, height, curb_weight, engine_size, compression_ratio, horsepower, peak_rpm, city_mpg, highway_mpg, price)

```


```{r}
summary(cars_filt)
```

## Train / Validation / Test Split

```{r}
train <- cars_filt
```

We work with a tiny dataset and apply crossvalidation. So all data is used for training (and implicitly validation).

# Modeling


## Lasso Regression

```{r}
train_x <- model.matrix(price ~ ., train)[, -14]
train_y <- train$price
lambdas <- 10^seq(3, -2, by = -.1)
model_lasso <- glmnet::cv.glmnet(x = train_x, 
                      y = as.matrix(train_y), 
                      family = "gaussian",
                      alpha = 1,  # Lasso
                      lambda = lambdas,
                      nfolds = 10
                      )
```

The next graph shows how shrinkage works.

```{r}
plot(model_lasso, label=T, xvar="lambda")
```

Lambda is varied between 0.001 and 1000. Here it is shown in logarithmic form. 

At lambda close to zero (left side) the coefficients are large. They are reduced if lambda is increased. For very large lambda the coefficients are reduced down to zero.

We need to find optimum lambda.

```{r}
lambda_opt <- model_lasso$lambda.min
```


Getting the coefficients:

```{r}
lasso_coef <- predict(model_lasso, 
                  s = lambda_opt, 
                  newx = val_x,
                  type = 'coefficients')
lasso_coef
```

Some parameters are set to zero and are thus removed from the model.

```{r}
model_lasso_single <- glmnet(train_x, train_y, family = "gaussian", alpha = 1, lambda = lambdas)
plot(model_lasso_single, label=T, xvar = "lambda")
```


## Ridge Regression

```{r}
model_ridge <- glmnet::cv.glmnet(x = train_x, 
                      y = as.matrix(train_y), 
                      family = "gaussian",
                      alpha = 0,  # Ridge
                      lambda = lambdas,
                      nfolds = 10
                      )
```

The next graph shows how shrinkage works.

```{r}
model_ridge <- glmnet::cv.glmnet(x = train_x, 
                      y = as.matrix(train_y), 
                      family = "gaussian",
                      alpha = 0,  # Ridge
                      lambda = lambdas,
                      nfolds = 10
                      )

plot(model_ridge, label=T, xvar="lambda")

```
Lambda is varied between 0.001 and 1000. Here it is shown in logarithmic form. 

At lambda close to zero (left side) the coefficients are large. They are reduced if lambda is increased. For very large lambda the coefficients are reduced down to zero.

We need to find optimum lambda:

```{r}
lambda_opt <- model_ridge$lambda.min
lambda_opt
```

Get the coefficients

```{r}
ridge_coef <- predict(model_ridge, 
                  s = lambda_opt, 
                  newx = val_x,
                  type = 'coefficients')
ridge_coef
```

Some parameters get close to zero, but never really match zero.

# Acknowledgement

Thanks to the creator/donor of the dataset.

Creator/Donor: 

Jeffrey C. Schlimmer (Jeffrey.Schlimmer '@' a.gp.cs.cmu.edu) 

Sources: 

1) 1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook. 
2) Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038 
3) Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037